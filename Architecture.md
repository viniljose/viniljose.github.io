
Architecture Versus Design : The difference between architecture and design is often a confusing one.Architecture is design, but not all design is architecture.
While we don’t want to wade into the never-ending argument about this distinction, we strive to provide an introduction to some of the Architectural Patterns & Design Principles.
architecture is an abstraction of a system.
The industry as a whole has struggled to precisely define “software architecture.” Some architects refer to software architecture as the blueprint of the system, while others define it as the roadmap for developing a system.Software architecture consists of the structure of the system  combined with architecture characteristics (“-ilities”) the system must support, architecture decisions, and finally design principles.The structure of the system refers to the type of architecture style the system is implemented in such as microservices.
The architecture characteristics define the success criteria of a system ie. the “-ilities” that the system must support.Architecture decisions define the rules for how a system should be constructed which direct the development teams on what is and what isn’t allowed.A design principle differs from an architecture decision in that a design principle is a guideline rather than a hard-and-fast rule.

Architectural patterns provide known solutions to a number of common problems in design.
A quality attribute (QA) is a measurable or testable property of a system that is used to indicate how well the system satisfies the needs of its stakeholders.
Availability refers to the ability of a system to mask or repair faults such that the cumulative service outage period does not exceed a required value over a specified time interval.” One of the most demanding tasks in building a high-availability, fault-tolerant system is to understand the nature of the failures that can arise during operation.Availability is closely related to security. A denial-of-service attack is explicitly designed to make a system fail—that is, to make it unavailable. A failure’s cause is called a fault.Faults can be prevented, tolerated, removed, or forecast. In this way a system becomes “resilient” to faults.
The distinction between faults and failures allows discussion of automatic repair strategies. That is, if code containing a fault is executed but the system is able to recover from the fault without any deviation from specified behavior being observable, there is no failure.
Performance, that is: It’s about time and the software system’s ability to meet timing requirements.Processing time:Processing consumes resources, which takes time.
Blocked time :A computation can be blocked because of contention for some needed resource.
Security is a measure of the system’s ability to protect data and information from unauthorized access while still providing access to people and systems that are authorized.

An event is a noteworthy thing that happens inside or outside of any business.EDA is typically based on an asynchronous message-driven communication model to propagate information throughout an enterprise.

A message consists of a header and a message body.
The header is a collection of name-value pairs, metadata that describes the data being sent.  unique message id generated by either the sender or the messaging infrastructure, and an optional return address, which specifies the message channel that a reply should be written to. The message body is the data being sent, in either text or binary format.

Reliability
The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error). The things that can go wrong are called faults, and systems that anticipate faults and can cope with them are called fault-tolerant or resilient.A fault is usually defined as one component of the system deviating from its spec, whereas a failure is when the system as a whole stops providing the required service to the user.It is impossible to reduce the probability of a fault to zero; therefore it is usually best to design fault-tolerance mechanisms that prevent faults from causing failures.
Hardware Faults:Hard disks crash, RAM becomes faulty, the power grid has a blackout, someone unplugs the wrong network cable.Our first response is usually to add redundancy to the individual hardware components in order to reduce the failure rate of the system.systems that can tolerate the loss of entire machines, by using software fault-tolerance techniques in preference or in addition to hardware redundancy.
Software Errors:Another class of fault is a systematic error within the system [8]. Such faults are harder to anticipate, and because they are correlated across nodes, they tend to cause many more system failures than uncorrelated hardware faults.There is no quick solution to the problem of systematic faults in software. Lots of small things can help: carefully thinking about assumptions and interactions in the system; thorough testing; process isolation; allowing processes to crash and restart; measuring, monitoring, and analyzing system behavior in production.
Human Errors:Design systems in a way that minimizes opportunities for error.make it easy to do “the right thing” and discourage “the wrong thing.” Decouple the places where people make the most mistakes from the places where they can cause failures.Test thoroughly at all levels.
Allow quick and easy recovery from human errors, to minimize the impact in the case of a failure. Set up detailed and clear monitoring.

Scalability
As the system grows (in data volume, traffic volume, or complexity), there should be reasonable ways of dealing with that growth.Even if a system is working reliably today, that doesn’t mean it will necessarily work reliably in the future.Scalability is the term we use to describe a system’s ability to cope with increased load.Load can be described with a few numbers which we call load parameters.e.g. it may be requests per second to a web server, the ratio of reads to writes in a database, the number of simultaneously active users in a chat room.
Performance:When you increase a load parameter and keep the system resources (CPU, memory, network bandwidth, etc.) unchanged, how is the performance of your system affected? When you increase a load parameter, how much do you need to increase the resources if you want to keep performance unchanged?
throughput—the number of records we can process per second.Latency and response time are often used synonymously, but they are not the same. The response time is what the client sees: besides the actual time to process the request (the service time), it includes network delays and queueing delays. Latency is the duration that a request is waiting to be handled.
avergae or arithmetic mean: given n values, add up all the values, and divide by n
median:If you take your list of response times and sort it from fastest to slowest, then the median is the halfway point.The median is also known as the 50th percentile, and sometimes abbreviated as p50.
the 95th, 99th, and 99.9th percentiles are common (abbreviated p95, p99, and p999). They are the response time thresholds at which 95%, 99%, or 99.9% of requests are faster than that particular threshold. For example, if the 95th percentile response time is 1.5 seconds, that means 95 out of 100 requests take less than 1.5 seconds, and 5 out of 100 requests take 1.5 seconds or more.
An SLA may state that the service is considered to be up if it has a median response time of less than 200 ms and a 99th percentile under 1s.
Some systems are elastic, meaning that they can automatically add computing resources when they detect a load increase, whereas other systems are scaled manually 

Maintainability
Over time, many different people will work on the system (engineering and operations, both maintaining current behavior and adapting the system to new use cases), and they should all be able to work on it productively.

Distributed Architecture Patterns
1. Single-node application into multiple containers
Goal of a container is to establish boundaries around specific resources (e.g., this application needs two cores and 8 GB of memory). Likewise, the boundary delineates team ownership (e.g., this team owns this image). Finally, the boundary is intended to provide separation of concerns (e.g., this image does this one thing).
In particular, they assume that all of the containers in the pattern can be reliably coscheduled onto a single machine. They also assume that all of the containers in the pattern can optionally share volumes or parts of their filesystems as well as other key container resources like network namespaces and shared memory. This tight grouping is called a pod in Kubernetes.

A.The Sidecar Pattern
The sidecar pattern is a single-node pattern made up of two containers. The first is the application container. It contains the core logic for the application. Without this container, the application would not exist. In addition to the application container, there is a sidecar container. The role of the sidecar is to augment and improve the application container, often without the application container’s knowledge.scheduled on the same machine, the application container and sidecar container share a number of resources, including parts of the filesystem, hostname and network, and many other namespaces.To be successful, the sidecar should be reusable across a wide variety of applications and deployments.

Applications and services often require related functionality, such as monitoring, logging, configuration, and networking services. These peripheral tasks can be implemented as separate components or services.Co-locate a cohesive set of tasks with the primary application, but place them inside their own process or container, providing a homogeneous interface for platform services across languages.This pattern is named Sidecar because it resembles a sidecar attached to a motorcycle. In a k8s pod like scenario the application container and sidecar container share a number of resources, including parts of the filesystem, hostname and network, and many other namespaces.

B.Ambassador pattern
 an ambassador container brokers interactions between the application container and the rest of the world.
 e.g 
 Using an Ambassador to Shard a Service
 Using an Ambassador for Service Brokering
 Using an Ambassador to Do Experimentation or Request Splitting
 request splitting is sometimes used to tee or split traffic such that all traffic goes to both the production system as well as a newer, undeployed version. The responses from the production system are returned to the user, while the responses from the tee-d service are ignored. Most often, this form of request splitting is used to simulate production load on the new version of the service without risking impact to existing production users.

https://docs.microsoft.com/en-us/azure/architecture/patterns/sidecar
